p8105\_hw2\_jx2371
================
Jingyu Xu
2018/10/5

Firstly，I set a globle option which hides the message and warning information.

``` r
knitr::opts_chunk$set(message = FALSE, warning = FALSE)
```

Problem 1
=========

read and clean the dataset
--------------------------

Firstly, a code chunck is writted to import the dataset

``` r
library(tidyverse)
NYC_Transit_data = read_csv(file = "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv")
```

Then, a code chunck is written to clean the data according to the reqirement. I name the manipulated dataset NYC\_Transit\_data1

``` r
NYC_Transit_data1=janitor::clean_names(NYC_Transit_data) %>%
  select(line:route11, entry, vending, entrance_type, ada)%>% #retain rows
  mutate(entry= ifelse(entry=="YES",TRUE,FALSE))#convert entry variable to logical variable
```

describe the dataset
--------------------

The original dataset contains variables including "Division, Line, Station Name, Station Latitude, Station Longitude, Route1, Route2, Route3, Route4, Route5, Route6, Route7, Route8, Route9, Route10, Route11, Entrance Type, Entry, Exit Only, Vending, Staffing, Staff Hours, ADA, ADA Notes, Free Crossover, North South Street, East West Street, Corner, Entrance Latitude, Entrance Longitude, Station Location, Entrance Location"
And the dataset we made some cleaning in the previous chunk contains variables including "line, station\_name, station\_latitude, station\_longitude, route1, route2, route3, route4, route5, route6, route7, route8, route9, route10, route11, entry, vending, entrance\_type, ada"

The original dataset contains variables including "Division, Line, Station Name, Station Latitude, Station Longitude, Route1, Route2, Route3, Route4, Route5, Route6, Route7, Route8, Route9, Route10, Route11, Entrance Type, Entry, Exit Only, Vending, Staffing, Staff Hours, ADA, ADA Notes, Free Crossover, North South Street, East West Street, Corner, Entrance Latitude, Entrance Longitude, Station Location, Entrance Location"

The data cleaning steps is described as following: 1)use janitor::clean\_names to transfer the variable names into lower snake case.
2)retain line, station, name, station latitude / longitude, routes served, entry, vending, entrance type, and ADA compliance.
3)convert the entry variable from character(YES VS NO) to a logical variable using ifelse function.

The dimension of the resulting dataset is 1868×19

I think the data is untidy, because some of the column names（route1-route11） are not names of variables, but still values of a variable. As a result of that, each row contains more than a single observation.

answers to dataset related questions
------------------------------------

1.There are 465 distinct stations.

2.There are 468staion that are ADA compliant.

3.The proportion of station entrance/exits without vending allow entrance is 0.0979657

4.a code chunk is wrote to reformat the data so that the route number and route name are distinct

``` r
gather(NYC_Transit_data1, key = route_number, value = route_name, route1:route11)
```

    ## # A tibble: 20,548 x 10
    ##    line  station_name station_latitude station_longitu~ entry vending
    ##    <chr> <chr>                   <dbl>            <dbl> <lgl> <chr>  
    ##  1 4 Av~ 25th St                  40.7            -74.0 TRUE  YES    
    ##  2 4 Av~ 25th St                  40.7            -74.0 TRUE  YES    
    ##  3 4 Av~ 36th St                  40.7            -74.0 TRUE  YES    
    ##  4 4 Av~ 36th St                  40.7            -74.0 TRUE  YES    
    ##  5 4 Av~ 36th St                  40.7            -74.0 TRUE  YES    
    ##  6 4 Av~ 45th St                  40.6            -74.0 TRUE  YES    
    ##  7 4 Av~ 45th St                  40.6            -74.0 TRUE  YES    
    ##  8 4 Av~ 45th St                  40.6            -74.0 TRUE  YES    
    ##  9 4 Av~ 45th St                  40.6            -74.0 TRUE  YES    
    ## 10 4 Av~ 53rd St                  40.6            -74.0 TRUE  YES    
    ## # ... with 20,538 more rows, and 4 more variables: entrance_type <chr>,
    ## #   ada <lgl>, route_number <chr>, route_name <chr>

5.Among the distinct stations, how many station serve the A train?

1.  Of the stations that serves A train, how many are ADA compliant?

Problem 2
=========

Mr. Trash Wheel Sheet
---------------------

Firstly, import the excel file and specify the Mr. Trash Wheel Sheet. I omit the note column by range function.

``` r
library(readxl)
trash_wheel= read_excel("./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = "Mr. Trash Wheel", range = cell_cols("A:N")) 
```

Then，a code chunk is written to use reasonable names of the Mr. Trash Sheet. I delete the unit of the variable name to make it more readable.

``` r
trash_wheel= janitor::clean_names(trash_wheel)#clean up the variables to the lower snake style
names(trash_wheel)#view the new variable name
```

    ##  [1] "dumpster"           "month"              "year"              
    ##  [4] "date"               "weight_tons"        "volume_cubic_yards"
    ##  [7] "plastic_bottles"    "polystyrene"        "cigarette_butts"   
    ## [10] "glass_bottles"      "grocery_bags"       "chip_bags"         
    ## [13] "sports_balls"       "homes_powered"

``` r
trash_wheel=select(trash_wheel, volume=volume_cubic_yards, weight=weight_tons, everything())
names(trash_wheel)# view the modified name
```

    ##  [1] "volume"          "weight"          "dumpster"       
    ##  [4] "month"           "year"            "date"           
    ##  [7] "plastic_bottles" "polystyrene"     "cigarette_butts"
    ## [10] "glass_bottles"   "grocery_bags"    "chip_bags"      
    ## [13] "sports_balls"    "homes_powered"

Now, a code chunk is written to omit the rows that do not include dumpster-specific data

``` r
trash_wheel_clean=filter(trash_wheel, !is.na(dumpster))
```

Then, we omit the rows that do not include dumpster-specific data and round the number of sports balls to the nearest integer and convert the result to an integer variable.

``` r
trash_wheel_clean=filter(trash_wheel,!is.na(dumpster))%>%
  mutate(sports_balls=round(sports_balls,digits = 0))%>%
  mutate(sports_balls=as.integer(sports_balls))
```

precipitation data for 2016 and 2017
------------------------------------

Now, we read the precipitatin data for 2016 and 2017. Also we use janitor::clean\_names to make the name more reasonable

``` r
precipitation_2016= read_excel("./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = "2016 Precipitation", range= cell_rows(2:15))
precipitation_2017= read_excel("./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = "2017 Precipitation", range= cell_rows(2:15))
precipitation_2016= janitor::clean_names(precipitation_2016)
precipitation_2017= janitor::clean_names(precipitation_2017)
```

omit the rows without precipitation data and add a variable year

``` r
precipitation_2016_clean=filter(precipitation_2016,!is.na(month)) %>%
mutate(year=2016)
```

``` r
precipitation_2017_clean=filter(precipitation_2017,!is.na(month)) %>%
mutate(year=2017)
```

now，combine the two datasets by month

``` r
combine_data = left_join(precipitation_2016_clean, precipitation_2017_clean, by = "month")%>%
mutate(month=month.name)
```

description of two datasets
---------------------------

And then caculate the median number of the sports balls in a dumpster in 2016

``` r
A=filter(trash_wheel_clean, year==2016)
median(A$sports_balls)
```

    ## [1] 26

The total preciitition in 2017 is 0

Problem 3
---------

import data

``` r
devtools::install_github("p8105/p8105.datasets")
```

``` r
library(p8105.datasets)
brfss=brfss_smart2010
```

data wrangling
--------------

We now write a code chunk to clean and restruct the data in the pipeline. The step is as follows: 1.format the data to use appropriate variable names
2.focus on the “Overall Health” topic
3.exclude variables for class, topic, question, sample size, and everything from lower confidence limit to GeoLocation
4.structure data so that values for Response (“Excellent” to “Poor”) are column names / variables which indicate the proportion of subjects with each response (which are values of Data\_value in the original dataset)
5.create a new variable showing the proportion of responses that were “Excellent” or “Very Good"".I name this variable as "above\_verygood"

``` r
brfss_data= brfss_smart2010 %>%
  janitor::clean_names() %>%
  filter(topic=="Overall Health") %>%
  select(-class, -topic, -question, -sample_size, -confidence_limit_low:-geo_location) %>%
  spread(key= response, value= data_value) %>% 
  janitor::clean_names() %>%
  mutate(over_verygood=excellent+ very_good)
```

answers to the dataset question
-------------------------------

1.  There are 404 unique locations included in the data set.
2.  THere are 51 state present， so all the states are presented in it.
