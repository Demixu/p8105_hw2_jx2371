---
title: "p8105_hw2_jx2371"
author: "Jingyu Xu"
date: "2018/10/5"
output: github_document
---

Firstly，I set a globle option which hides the message and warning information.
```{r setup}
knitr::opts_chunk$set(message = FALSE, warning = FALSE)
```

#Problem 1
##read and clean the dataset
Firstly, a code chunck is writted to import the dataset
```{r import data1}
library(tidyverse)
NYC_Transit_data = read_csv(file = "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv")
```

Then, a code chunck is written to clean the data according to the reqirement. I name the manipulated dataset NYC_Transit_data1
```{r data cleaning}
NYC_Transit_data1=janitor::clean_names(NYC_Transit_data) %>%
  select(line:route11, entry, vending, entrance_type, ada)%>% #retain rows
  mutate(entry= ifelse(entry=="YES",TRUE,FALSE))#convert entry variable to logical variable
```

##describe the dataset 
The original dataset contains variables including "`r names(NYC_Transit_data)`"   
And the dataset we made some cleaning in the previous chunk contains variables including "`r names(NYC_Transit_data1)`"  

The original dataset contains variables including "`r names(NYC_Transit_data)`"   

The data cleaning steps is described as following:
1)use janitor::clean_names to transfer the variable names into lower snake case.    
2)retain line, station, name, station latitude / longitude, routes served, entry, vending, entrance type, and ADA compliance.    
3)convert the entry variable from character(YES VS NO) to a logical variable using ifelse function. 

The dimension of the resulting dataset is `r dim(NYC_Transit_data1)[1]`&times;`r dim(NYC_Transit_data1)[2]`  

I think the data is untidy, because some of the column names（route1-route11） are not names of variables, but still values of a variable. As a result of that, each row contains more than a single observation.

##answers to dataset related questions
1.There are `r nrow(distinct(NYC_Transit_data1, line, station_name))` distinct stations. 

2.There are `r length(which(NYC_Transit_data1$ada==TRUE))`staion that are ADA compliant.  

3.The proportion of station entrance/exits without vending allow entrance is `r   length(which(NYC_Transit_data1$vending=="NO"))/length(NYC_Transit_data1$vending)` 

4.a code chunk is wrote to reformat the data so that the route number and route name are distinct
```{r}
gather(NYC_Transit_data1, key = route_number, value = route_name, route1:route11)
```

5.Among the distinct stations, how many station serve the A train?


6. Of the stations that serves A train, how many are ADA compliant?


#Problem 2
## Mr. Trash Wheel Sheet
Firstly, import the excel file and specify the Mr. Trash Wheel Sheet. I omit the note column by range function. 
```{r}
library(readxl)
trash_wheel= read_excel("./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = "Mr. Trash Wheel", range = cell_cols("A:N")) 
```

Then，a code chunk is written to use reasonable names of the Mr. Trash Sheet. I delete the unit of the variable name to make it more readable.
```{r}
trash_wheel= janitor::clean_names(trash_wheel)#clean up the variables to the lower snake style
names(trash_wheel)#view the new variable name
trash_wheel=select(trash_wheel, volume=volume_cubic_yards, weight=weight_tons, everything())
names(trash_wheel)# view the modified name
```

Now, a code chunk is written to omit the rows that do not include dumpster-specific data
```{r}
trash_wheel_clean=filter(trash_wheel, !is.na(dumpster))
```

Then, we omit the rows that do not include dumpster-specific data and round the number of sports balls to the nearest integer and convert the result to an integer variable.
```{r}
trash_wheel_clean=filter(trash_wheel,!is.na(dumpster))%>%
  mutate(sports_balls=round(sports_balls,digits = 0))%>%
  mutate(sports_balls=as.integer(sports_balls))
```

## precipitation data for 2016 and 2017
Now, we read the precipitatin data for 2016 and 2017. Also we use janitor::clean_names to make the name more reasonable
```{r}
precipitation_2016= read_excel("./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = "2016 Precipitation", range= cell_rows(2:15))
precipitation_2017= read_excel("./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = "2017 Precipitation", range= cell_rows(2:15))
precipitation_2016= janitor::clean_names(precipitation_2016)
precipitation_2017= janitor::clean_names(precipitation_2017)
```

omit the rows without precipitation data and add a variable year
```{r precipitation_2016}
precipitation_2016_clean=filter(precipitation_2016,!is.na(month)) %>%
mutate(year=2016)
```

```{r}
precipitation_2017_clean=filter(precipitation_2017,!is.na(month)) %>%
mutate(year=2017)
```


now，combine the two datasets by month
```{r}
combine_data = left_join(precipitation_2016_clean, precipitation_2017_clean, by = "month")%>%
mutate(month=month.name)
```

## description of two datasets
And then caculate the median number of the sports balls in a dumpster in 2016
```{r}
A=filter(trash_wheel_clean, year==2016)
median(A$sports_balls)
```

The total preciitition in 2017 is `r sum(combine_data$total_2017)`

## Problem 3
import data
```{r}
devtools::install_github("p8105/p8105.datasets")
```

```{r}
library(p8105.datasets)
brfss=brfss_smart2010
```

##data wrangling
We now write a code chunk to clean and restruct the data in the pipeline. The step is as follows:
1.format the data to use appropriate variable names  
2.focus on the “Overall Health” topic  
3.exclude variables for class, topic, question, sample size, and everything from lower confidence limit to GeoLocation  
4.structure data so that values for Response (“Excellent” to “Poor”) are column names / variables which indicate the proportion of subjects with each response (which are values of Data_value in the original dataset)  
5.create a new variable showing the proportion of responses that were “Excellent” or “Very Good"".I name this variable as "above_verygood"
```{r}
brfss_data= brfss_smart2010 %>%
  janitor::clean_names() %>%
  filter(topic=="Overall Health") %>%
  select(-class, -topic, -question, -sample_size, -confidence_limit_low:-geo_location) %>%
  spread(key= response, value= data_value) %>% 
  janitor::clean_names() %>%
  mutate(over_verygood=excellent+ very_good)
```

##answers to the dataset question
1. There are `r nrow(distinct(brfss_data, locationdesc))` unique locations included in the data set.
2. THere are `r nrow(distinct(brfss_data, locationabbr))` state present， so all the states are presented in it.

